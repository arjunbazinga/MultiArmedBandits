# MultiArmedBandits
Python implementation of Multi armed bandits, with agent classes and arms for rapid experimentation. Mostly fun!


Interactive Version!! [here]( https://beta.mybinder.org/v2/gh/arjunbazinga/MultiArmedBandits/master?filepath=Multi-Armed-Bandits.ipynb), Thanks Binder!

Check notebook [here](https://nbviewer.jupyter.org/github/arjunbazinga/MultiArmedBandits/blob/master/Multi-Armed-Bandits.ipynb)
